## A Survey of LLM-based Agents: Theories, Technologies, Applications and Suggestions


### 理论基础

早期Agent基于强化学习,认为AI智能体可以基于简单的启发式驱动策略函数行动。然而，基于强化学习的智能体可能面临一些障碍[3]，如训练时间长、采样效率低和学习过程不稳定等。

由于具备卓越的多模态理解与生成能力、无与伦比的知识获取与推理能力，以及大语言模型（LLMs）的灵活性和可扩展性，人工智能Agent将LLMs作为核心大脑，试图实现人类水平的感知、认知和行为[5]。

多模态感知实现自主感知能力,复杂的规划实现自发工作能力,可行的具身化或工具利用实现反应能力,有效的多元化记忆实现交互能力。

- 模态编码器（Modality Encoder）：输入多模态原始数据,编码出其他模态的特征向量。
- 模态连接器（Modality Connector）：将模态数据和文本编码数据融合,实现对齐,输出对齐后的模态特征。
- LLM主干（LLM Backbone）：
- 输出投影器（Output Projector）
- 模态生成器（Modality Generator）

？？？不是一个LLM的主干,像是文生图的workflow

任务目标g、环境e、提示集p及语言模型总体参数Θ后，任务分解可形式化表示为[8]：g₀,g₁,...,gₙ = decp(g,e,p,Θ)

其中"decp"表示分解操作，g₀,g₁,...,gₙ代表子目标。Agent应支持通过CoT实现的单路径和多路径推理能力。

根据内外双重对齐来进行多路径推理的选择：外部对齐需要将人类意图或预期目标转化为基于大语言模型智能体的训练目标，通常采用包含监督微调、奖励建模和策略优化的RLHF方法；内部对齐则要求规划过程确保内部优化目标与智能体训练目标保持一致，具体强调通过安全评估、可解释性验证和人类价值观检验来保障规划的对齐性。

然后就是RAG通过外部知识库增强记忆与知识调用能力。

以及例如API调用、代码解释器乃至具身化工具的工具使用能力。

论文首先回顾了支撑 LLM-based Agent 的几大核心理论：

### 关键技术
论文将 LLM-based Agent 的技术架构归纳为四大模块：

感知（Perception）：处理文本、图像、音频、视频等多模态输入，如 BLIP-2、MiniGPT-4、AudioGPT 等。

规划（Planning）：包括任务分解、单/多路径推理（如 CoT、ToT、GoT）、反思机制（如 Reflexion、CRITIC）等，提升决策合理性。

记忆（Memory）：涵盖交互内记忆、跨交互记忆和外部知识。

- 内部交互记忆指单次交互内的历史信息
- 跨交互记忆指跨越多轮交互积累的长期历史信息
- 或是通过RAG技术获取高质量外部知识

行动（Action）：进行工具理解、工具调用、工具整合的能力。

### 应用与评估

LLM-based Agent 已广泛应用于多个领域：

自然科学：数学（ToRA）、化学（ChemCrow）、生物学（BSDG）；

社会科学：经济学（Alpha-GPT）、法律（LJP-Agent）、心理学（Replika-MWS）；

工程领域：代码生成（GPT-Engineer、AutoGen）、游戏（Voyager、GITM）、工业规划（LLM-Planner）；

评估基准：如 AgentBench（多环境评估）、ToolLLM（工具使用）、SafetyBench（安全性）、AlignBench（中文对齐）等。

### 挑战与建议

作者指出当前 LLM-based Agent 面临的关键挑战，并提出四点建议：

突破内在限制：如幻觉、长上下文处理、多模态推理等；

推动规模化多智能体系统：实现动态调度与高效协作；

强化可控的 AI 对齐：确保遵守法律、伦理与人类价值观；

构建统一综合的评估体系：当前评估分散，亟需标准化平台。

## Survey on evaluation of llm Agent

分为4块。

1. 对agent基本能力的评估（规划和多步推理能力、函数调用和工具使用、自反思、记忆能力）
2. 领域特长能力的评估（web agent、编程Agent、科学推理Agent、对话Agent）
3. Agent在泛用领域的评估
4. 评估Agent 的框架（开发用框架和练习场式环境的框架。）


### 基本能力评估

#### 规划和多步推理能力

大语言模型中的多步推理通常需要执行序列化的逻辑操作（一般涉及3-10个中间步骤）来获得无法通过单步推断得出的解决方案。下列测试用于评价模型在特定领域的推理能力：

- 数学推理：GSM8K,MATH,AQUA-RAT
- 多跳问答：HotpotQA,StrategyQA、MultiRC
- 科学推理：ARC
- 逻辑推理：FOLIO和P-FOLIO
- 约束满足谜题：24点
- 日常尝试：MUSR
- 高难度推理任务:BBH

一些评价规划能力的新基准（2023）：

- ToolEmu:采用基于模拟器的方法评估工具使用型智能体。说明了成功规划需要显式状态追踪和错误恢复能力。
- MINT：针对交互环境中的规划进行评估。发现即使先进的大语言模型也难以应对需要多步骤的长期任务。
- PlanBench：跨领域综合评估框架，表明当前模型擅长短期战术规划但拙于长期战略规划。
- AutoPlanBench：聚焦日常场景的规划评估。证明最前沿的大语言模型智能体仍落后于传统符号规划器。

符号规划任务表现不佳(2024)：

- FlowBench：评估工作流规划能力，重点关注专业知识密集型任务。
- ACPBench：评估大语言模型的核心推理技能。
- NaturalPlan：评估大语言模型如何处理自然语言呈现的现实世界规划任务

这些测试凸显了Agent高效规划所需要的核心能力：

（1）任务分解能力以拆解复杂问题，

（2）状态追踪与信念维护能力以实现精准多步推理，

（3）自我纠错机制以识别并修正错误，

（4）因果理解能力以预测行动结果，

（5）元规划能力以优化决策策略。

#### 函数调用与工具使用

早期研究采用针对性工具，例如通过增强检索能力的语言模型实现检索功能。后续发展则包含更多通用工具，如ToolFormer、Chameleon和MRKL。

一些提供明确参数进行简单交互为内容的评估方法：

- ToolAIpaca 2023
- APIBench 2025
- ToolBench 2023
- BFCL 2024

它们使用合成数据集和基于规则的匹配来建立通过率和结构准确性等基线指标。但在现实应用中有所局限。例如参数可能在多轮对话、对话中未明确提及，或是工具有复杂输入结构和冗长精密输出。

BFCL通过引入组织工具（BFCL v2）和整合多轮多步骤评估逻辑（BFCL v3）来更贴近真实问题复杂性，并强调持续状态管理的重要性。

新的基准测试：

- ToolSandbox：整合有状态工具执行、隐式状态依赖、基于策略的对话评估以及针对任意轨迹中里程碑节点的动态评估策略。
- Seal-Tools：采用自指导方法生成嵌套工具调用，有效建模层级化交互场景。
- API-Bank：通过对话式评估和海量训练数据集强化真实API交互模拟
- ComplexFuncBench：评估隐式参数推理、用户约束遵循及长上下文高效处理等场景。


#### 自我反思

交互式自我反思：

- LLF-Bench
- LLM-Evolve
- Reflection-Bench
- LiveCodeBench：编程基准
- APPS：编程基准

#### 记忆

新的研究引入了记忆机制。如ReadAgent、MemGPT和A-MEM探索了这类方法。

ReadAgent通过内容分组、将事件浓缩为记忆单元并进行段落检索来结构化阅读流程，其有效性已在QUALITY、NarrativeQA和QMSum等数据集上得到验证。类似地，A-MEM提出了一种采用LoCoMo基准评估的高级记忆架构，而MemGPT则采用分层记忆系统，并在NaturalQuestions-Open和多轮对话数据集上进行了测试。

一些新的基准测试：

- LTM-BenchMark
- RAISE
- KARMA

### 特定领域评估

Agent基准测试通过整合三大核心要素，为评估基于大语言模型的Agent提供了系统化框架：首先采用明确定义的任务数据集说明智能体的预期目标；其次构建运行环境（模拟静态/动态场景或真实世界），可集成用户模拟、多样化工具及特定策略；最后运用成功率、效率、精确度等评估指标进行多维度量，支持从单个操作追踪到端到端任务完成的多颗粒度分析。

#### Web Agent

这类AI系统专为网站交互设计，可执行机票预订、商品采购等任务。评估重点包括任务完成效率、网络环境导航能力及安全合规表现。随着Agent进步，评估基准也同步发展，最新成果已能模拟日趋复杂的现实交互场景。

早期研究聚焦基础模拟环境，如MiniWob和MiniWoB++。

后续研究在静态数据集开发上取得突破，支持离线可复现评估。如WebShop。后续的Mind2Web与WebVoyager支持对复杂网站结构导航能力和阶段性目标达成度的综合测评。

近期研究已转向更贴近现实环境的动态在线基准测试。

- WebLinX：提出动态交互模型，要求Agent必须适应网页界面的持续变化，从而检验其决策流程的鲁棒性。
- WebArena/Visual-WebArena:整合了真实用户界面元素与视觉线索，要求Agent不仅能遵循预设流程，还需解读并响应视觉信息。
- ST-WebAgentBench:尝试在静态与动态元素融合的环境中评估网络Agent，揭示其在多变条件下的表现。

#### Code Agent

- SWE-bench基于真实GitHub问题构建，提供端到端评估框架，包括详细的问题描述、完整代码库、执行环境（如Docker）和验证测试。
- SWE-bench Lite聚焦300个涉及缺陷修复的子任务，剔除需复杂多文件修改或无关元素的任务.
- SWE-bench LiteS通过移除存在精确补丁或描述不充分的任务进一步优化数据集.
- SWE-bench Verified仅保留描述清晰且测试用例完备的问题。
- SWE-bench+致力于缓解解决方案泄露和弱测试用例等关键评估缺陷
- SWE-bench Multimodal则针对含可视化元素的JavaScript应用，评估Agent在视觉软件领域的表现。
- SWT-Bench、TDD-Bench Verified专注于评估Agent根据GitHub问题生成测试用例的能力。
- ITBench为评估复杂现实IT自动化任务提供基准。
- SWELancer通过对接自由编程任务，将Agent表现与货币价值挂钩，凸显了在复杂现实场景中实现长期推理与决策的挑战。


#### Science Agent

科学智能体的评估已从早期测试基础推理能力的基准，逐步发展为衡量多样化科研能力的综合框架。

初期基准侧重科学知识记忆与推理能力或是科学文献的整合和情景化分析:

- ARC
- ScienceQA
- ScienceWorld

- QASPER
- QASA
- MS²
- SciRiff进一步拓展评估维度，强调智能体跨科学领域执行用户指令的能力。

当前研究趋势转向开发能加速科研进程的科学智能体，基准已覆盖科研全流程:

1. 科学构思：评估智能体能否自主提出媲美人类专家的创新性研究构想，重点关注科学思维的创造性、相关性与可行性；（Si等，2025）
2. 实验设计：AAAR-1.0数据集等基准测试智能体系统规划实验的能力，包括假设构建、方法选择及符合科学规范的实验流程设计；
3. 实验代码生成：SciCode、ScienceAgentBench、SUPER和CORE-Bench等基准验证智能体生成精准可执行代码的能力，确保代码符合科学协议要求并保持计算准确性；
4. 同行评审生成：测试智能体能否提供超越人类评审质量的深度反馈（Chamoun等，2024）。

整合上列流程的基准：AAAR-1.0、MLGym、DiscoveryWorld、LAB-Bench


#### Chat Agent

略

### 通用能力评估

Agent 正从特定应用场景转向更通用的方向。这些Agent将大语言模型的核心能力与网页浏览、信息检索、代码执行等技能相结合，来解决复杂任务。

- GAIA基准：包含466个人工设计的现实世界问题，用于测试智能体的推理、多模态理解、网页浏览和通用工具使用能力。
- Galileo Agent排行榜：着重评估智能体在数据库查询、在线计算器和网络服务等现实应用中执行函数调用和API调用的能力。
- AgentBench:引入了一套包含操作系统命令、SQL数据库、数字游戏和家务任务的交互环境。

或是聚焦于在全功能计算机操作环境中的表现：

OSWorld、OmniACT和AppWorld等基准测试智能体能否驾驭真实计算机系统、执行复杂任务并协调跨多应用程序的操作。

### Agent 评估框架
略

### 讨论

评估指标正向真实环境和挑战性看齐。

另一方面，新型的方向有

1. 精细化评估推进：缺乏对工具选择、推理质量等中间决策过程的细粒度分析。
2. 成本效率指标：将Token用量、API开销、推理时间等成本效率作为核心指标。
3. 规模化与自动化：采用合成数据生成技术创建多样化任务场景；发展"智能体即评委"的LLM自动化评估。
4. 安全合规性：当前基准对安全性、可信度及政策合规的关注有限。

## Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review

作者对153篇LLM有关的CHI会议的论文集进行研究。专注于LLM在人机交互领域的应用。

### 应用领域

1. 沟通和写作：许多研究将作家视为大型语言模型的目标用户，任务范围从个人日记、电子邮件撰写到故事创作、剧本编写以及一般创意写作。
2. **能力增强**：这一领域包括开发技术以通过改变我们与技术及信息的互动方式来提升人类表现和生产力的论文。
3. 教育：这一领域探索了大型语言模型在提升学生学习体验和改进教育者教学方法方面的潜力。
4. 责任：考虑计算系统对社会、伦理领域的影响，尤其是高风险领域。
5. 编程：聚焦于软件工程和编程领域
6. 语言模型的可靠和有效性：关注于评估和提升llm输出本身
7. 健康：关注于通过llm获取健康相关疾病和病症的管理与预防的知识或是处理健康数据。
8. 设计：用于提供设计有关的帮助，如用户界面设计。
9. 无障碍和老龄化：该领域重点关注残障人士和老年人群体。
10. 创造：该领域涵盖了创意过程及创造力支持工具。

### 应用角色

1. LLM作为系统引擎：在这一角色中，LLM作为系统、原型、算法和编程框架的核心元素发挥作用。
2. LLM作为研究工具：使用LLM执行传统上由研究人员或研究助理完成的任务，包括数据收集、分析或写作。
3. LLM作为参与者或用户：此类研究用大语言模型模拟人类响应和行为。
4. LLM作为研究对象：此类研究探讨大语言模型底层机制与特性的论文，涉及训练数据集、响应输出及问题研究（如幻觉现象）。
5. 用户对LLM的认知：此类包括关于用户如何看待LLMs或LLM驱动工具的研究。

### 不足之处

1. LLM对不同人物存在偏见：大语言模型对不同人群的回复存在差异。
2. LLM训练数据覆盖范围不足：大语言模型的训练数据可能不足或过时。
3. LLM可能输出多种回答：大语言模型的回答具有概率性特征，即使输入相同的提示，其输出仍可能发生不可预测的变化。
4. LLM可能产生幻觉：大语言模型可能产生不准确或完全虚构的信息。
5. LLM的错误或偏差无从查询：由于模型的黑箱性质，大语言模型的输出存在异常时，难以定位出现异常的原因。

6. LLM的计算要求严苛
7. 使用LLM对经济也有要求。
8. LLM缺乏评估标准或度量。

9. 在不同用户和不同情境中，LLM使用过程中的内部效度和外部效度存在差异。
10. 不同的LLM存在效度差异。
11. 提示词也会带来效度差异。

12. LLM可能会带来就业问题。
13. LLM的表示偏差可能会带来认知引导方面的负面效果。
14. LLM的输出可能虚假、带有误导性或是无意义、低质量。
15. LLM可能会用于恶意行为。
16. LLM可能会输出仇恨言论。
17. LLM对电力的消耗引起环境危害。
